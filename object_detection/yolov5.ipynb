{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039eee26-3740-46ec-94a3-e6988f7a1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "from helpers import *\n",
    "from dataset_helpers import *\n",
    "import torch\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799524cd-2bf9-4c41-b610-b68c4b68cc5d",
   "metadata": {},
   "source": [
    "### Yolo5 for V3C dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c9500e-aca2-40e6-99a1-a0b7c2d00fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all image names ...\n",
      "Number of images:  2508110\n"
     ]
    }
   ],
   "source": [
    "data = dataset(dataset_name='V3C')\n",
    "data.get_file_name()\n",
    "print(\"Number of images: \", len(data.image_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e90cea24-4f33-429d-a6b1-b8db5fe091c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name_path = osp.join(DATASET_MASTER_PATH, 'indices')\n",
    "with open(osp.join(video_name_path, 'video_indices.txt'), 'r') as file:\n",
    "    video_indices = file.read().splitlines()\n",
    "\n",
    "for video in video_indices:\n",
    "    curr_path = osp.join(DATASET_MASTER_PATH, 'object_detection/labels', video)\n",
    "    if not osp.isdir(curr_path):\n",
    "        os.mkdir(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf4b133-1c84-41af-9f94-6785573cc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='object_detection/yolov5_models/yolov5m.pt')\n",
    "\n",
    "for item in tqdm(data.image_names):\n",
    "    concepts = convert_to_concepts(item)\n",
    "    label_curr_path = osp.join(DATASET_MASTER_PATH, 'object_detection/labels', concepts['video'])\n",
    "    image_curr_path = osp.join(DATASET_MASTER_PATH, 'object_detection/images', concepts['video'])\n",
    "    detection = model(item) \n",
    "    temp = detection.save(image_curr_path)\n",
    "    bbox = detection.pandas().xyxy[0]\n",
    "    save_df_to_json(bbox, osp.join(label_curr_path, '{0}.json'.format(concepts['filename'][:-4])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00074148-47d6-4709-833f-851cc3d8a24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbs",
   "language": "python",
   "name": "vbs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
